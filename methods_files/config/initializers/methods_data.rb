# frozen_string_literal: true

ML_METHODS = [
  # â”€â”€ PHASE 1 : APPRENDRE â”€â”€
  {
    method: ".fit(X_train, y_train)",
    phase: "Apprendre",
    phase_icon: "ğŸ§ ",
    phase_color: "purple",
    short: "Apprend des donnÃ©es. MÃ©morise les paramÃ¨tres internes.",
    explain: "C'est LE moment oÃ¹ le modÃ¨le regarde les donnÃ©es et en tire quelque chose. Un scaler mÃ©morise la moyenne et l'Ã©cart-type. Un arbre mÃ©morise les rÃ¨gles de dÃ©cision. Un rÃ©seau de neurones ajuste ses poids.",
    examples: [
      { context: "Scaler", code: "scaler.fit(X_train)", learns: "MÃ©morise Î¼=102 et Ïƒ=48 pour la colonne surface" },
      { context: "Encoder", code: 'encoder.fit(X_train[["city"]])', learns: "MÃ©morise les catÃ©gories : Paris, Lyon, Marseille, Nancy" },
      { context: "ModÃ¨le", code: "model.fit(X_train, y_train)", learns: "Apprend les coefficients / poids / rÃ¨gles" },
      { context: "PCA", code: "pca.fit(X_train)", learns: "Trouve les axes de variance maximale" },
      { context: "KMeans", code: "km.fit(X_train)", learns: "Place les centroÃ¯des des clusters" },
    ],
    rule: "âš ï¸ TOUJOURS sur X_train (jamais X_test). Sinon = data leakage.",
    frameworks: ["sklearn", "keras", "xgboost"],
  },
  {
    method: ".compile(optimizer, loss, metrics)",
    phase: "Apprendre",
    phase_icon: "ğŸ§ ",
    phase_color: "purple",
    short: "Configure le mode d'apprentissage AVANT le .fit(). Keras uniquement.",
    explain: "Le .compile() ne touche pas aux donnÃ©es. Il dit au rÃ©seau : 'VoilÃ  comment tu vas apprendre'. C'est le mode d'emploi du .fit(). On choisit l'optimizer (comment ajuster les poids), la loss (quoi minimiser), et les mÃ©triques (quoi surveiller).",
    examples: [
      { context: "Classification binaire", code: 'model.compile(optimizer="adam", loss="binary_crossentropy", metrics=["accuracy"])', learns: "Adam + crossentropy + accuracy" },
      { context: "RÃ©gression", code: 'model.compile(optimizer="adam", loss="mse", metrics=["mae"])', learns: "Adam + MSE + MAE" },
      { context: "Multi-classes", code: 'model.compile(optimizer="adam", loss="categorical_crossentropy")', learns: "Adam + categorical crossentropy" },
    ],
    rule: "Obligatoire AVANT .fit() en Keras. N'existe pas en sklearn (tout est dans le constructeur).",
    frameworks: ["keras"],
  },

  # â”€â”€ PHASE 2 : TRANSFORMER â”€â”€
  {
    method: ".transform(X)",
    phase: "Transformer",
    phase_icon: "ğŸ”„",
    phase_color: "cyan",
    short: "Applique la transformation apprise au .fit(). Ne rÃ©-apprend PAS.",
    explain: "L'objet utilise ce qu'il a mÃ©morisÃ© au .fit() pour transformer de nouvelles donnÃ©es. Le scaler applique (x âˆ’ Î¼) / Ïƒ avec le Î¼ et Ïƒ du train. L'encoder remplace les catÃ©gories par les codes appris.",
    examples: [
      { context: "Scaler", code: "X_test_sc = scaler.transform(X_test)", learns: "Applique (x âˆ’ 102) / 48 (valeurs du train)" },
      { context: "Encoder", code: "encoded = encoder.transform(X_test)", learns: "Encode avec les catÃ©gories vues au fit" },
      { context: "PCA", code: "X_pca = pca.transform(X_test)", learns: "Projette sur les axes trouvÃ©s au fit" },
    ],
    rule: "âš ï¸ Ne JAMAIS utiliser .fit_transform() sur X_test. Toujours .transform() seul.",
    frameworks: ["sklearn"],
  },
  {
    method: ".fit_transform(X_train)",
    phase: "Transformer",
    phase_icon: "ğŸ”„",
    phase_color: "cyan",
    short: "Raccourci : .fit() + .transform() en une ligne. UNIQUEMENT sur le train.",
    explain: "Fait les deux opÃ©rations d'un coup : apprend les paramÃ¨tres ET applique la transformation. C'est un raccourci pratique, mais il ne doit Ãªtre utilisÃ© QUE sur le train. Sur le test, on utilise .transform() seul.",
    examples: [
      { context: "Train", code: "X_train_sc = scaler.fit_transform(X_train)", learns: "Apprend Î¼/Ïƒ du train ET transforme" },
      { context: "Test", code: "X_test_sc = scaler.transform(X_test)", learns: "RÃ©utilise Î¼/Ïƒ du train (pas de fit !)" },
    ],
    rule: "âš ï¸ RÃ‰SERVÃ‰ au train set. C'est la source #1 de data leakage chez les dÃ©butants.",
    frameworks: ["sklearn"],
  },

  # â”€â”€ PHASE 3 : PRÃ‰DIRE â”€â”€
  {
    method: ".predict(X)",
    phase: "PrÃ©dire",
    phase_icon: "ğŸ¯",
    phase_color: "green",
    short: "Donne la rÃ©ponse du modÃ¨le : une classe ou une valeur.",
    explain: "Le modÃ¨le utilise ce qu'il a appris pour donner une rÃ©ponse. En classification, c'est la classe (0 ou 1). En rÃ©gression, c'est la valeur (245 000 â‚¬). En Keras, c'est la probabilitÃ© brute (il faut arrondir soi-mÃªme).",
    examples: [
      { context: "RÃ©gression", code: "y_pred = model.predict(X_test)", learns: "[245000, 182000, 320000, ...]" },
      { context: "Classification sklearn", code: "y_pred = model.predict(X_test)", learns: "[0, 1, 0, 1, ...] (classes directement)" },
      { context: "Classification Keras", code: "probas = model.predict(X_test)", learns: "[0.92, 0.15, 0.87, ...] (probabilitÃ©s)" },
      { context: "KMeans", code: "labels = km.predict(X_new)", learns: "[2, 0, 3, 1, ...] (numÃ©ro de cluster)" },
    ],
    rule: "Toujours aprÃ¨s .fit(). Si le modÃ¨le n'a pas appris, erreur.",
    frameworks: ["sklearn", "keras", "xgboost"],
  },
  {
    method: ".predict_proba(X)",
    phase: "PrÃ©dire",
    phase_icon: "ğŸ¯",
    phase_color: "green",
    short: "Donne la probabilitÃ© de chaque classe. Sklearn uniquement.",
    explain: "Au lieu de dire '1' ou '0', donne la confiance du modÃ¨le. Indispensable pour ajuster le seuil de dÃ©cision, tracer la courbe ROC, et Ã©valuer l'AUC.",
    examples: [
      { context: "Binaire", code: "probas = model.predict_proba(X_test)[:, 1]", learns: "[0.92, 0.15, 0.87, 0.34, ...]" },
      { context: "Seuil custom", code: "y_pred = (probas >= 0.3).astype(int)", learns: "Seuil abaissÃ© â†’ plus de dÃ©tection, moins de precision" },
    ],
    rule: "Le [:, 1] prend la proba de la classe positive. Indispensable pour ROC/AUC.",
    frameworks: ["sklearn"],
  },
  {
    method: ".fit_predict(X)",
    phase: "PrÃ©dire",
    phase_icon: "ğŸ¯",
    phase_color: "green",
    short: "Raccourci : .fit() + .predict() en une ligne. Pour le clustering.",
    explain: "SpÃ©cifique au non-supervisÃ© (KMeans, DBSCAN). Apprend les clusters ET assigne les labels en une fois.",
    examples: [
      { context: "KMeans", code: "labels = km.fit_predict(X_sc)", learns: "[0, 2, 1, 3, 0, 2, ...]" },
    ],
    rule: "Ã‰quivalent de km.fit(X) puis km.predict(X), mais plus concis.",
    frameworks: ["sklearn"],
  },

  # â”€â”€ PHASE 4 : Ã‰VALUER â”€â”€
  {
    method: ".score(X, y)",
    phase: "Ã‰valuer",
    phase_icon: "ğŸ“",
    phase_color: "yellow",
    short: "Ã‰value la performance. Accuracy (classif) ou RÂ² (rÃ©gression). Sklearn uniquement.",
    explain: "Raccourci qui fait predict + calcul de la mÃ©trique par dÃ©faut. Pour la classification c'est l'accuracy, pour la rÃ©gression c'est le RÂ². Pratique mais limitÃ© â€” souvent on prÃ©fÃ¨re les mÃ©triques spÃ©cifiques.",
    examples: [
      { context: "Train", code: "model.score(X_train, y_train)", learns: "0.952 (accuracy ou RÂ² sur le train)" },
      { context: "Test", code: "model.score(X_test, y_test)", learns: "0.918 (performance rÃ©elle)" },
      { context: "Comparaison", code: "train vs test proche â†’ pas d'overfitting", learns: "" },
    ],
    rule: "Train >> Test = overfitting. Train â‰ˆ Test = modÃ¨le stable.",
    frameworks: ["sklearn"],
  },
  {
    method: ".evaluate(X, y)",
    phase: "Ã‰valuer",
    phase_icon: "ğŸ“",
    phase_color: "yellow",
    short: "Calcule la loss ET les mÃ©triques sur un dataset. Keras uniquement.",
    explain: "Ã‰quivalent Keras du .score() mais plus riche : renvoie la loss (ce que le modÃ¨le minimise) ET toutes les mÃ©triques dÃ©finies au .compile().",
    examples: [
      { context: "Ã‰valuation", code: "loss, acc = model.evaluate(X_test, y_test)", learns: "loss=0.147, accuracy=0.924" },
    ],
    rule: "Toujours sur le test set pour la performance finale.",
    frameworks: ["keras"],
  },
  {
    method: "cross_val_score(model, X, y, cv=5)",
    phase: "Ã‰valuer",
    phase_icon: "ğŸ“",
    phase_color: "yellow",
    short: "Ã‰value K fois en changeant le fold de validation. Mesure la stabilitÃ©.",
    explain: "DÃ©coupe les donnÃ©es en K morceaux. EntraÃ®ne K fois en laissant 1 morceau de cÃ´tÃ©. Renvoie K scores â†’ la moyenne et l'Ã©cart-type mesurent la fiabilitÃ© du modÃ¨le.",
    examples: [
      { context: "Cross-val", code: 'cv = cross_val_score(model, X, y, cv=5, scoring="r2")', learns: "[0.82, 0.85, 0.83, 0.84, 0.81]" },
      { context: "RÃ©sumÃ©", code: 'f"RÂ² = {cv.mean():.3f} Â± {cv.std():.3f}"', learns: "RÂ² = 0.830 Â± 0.014 â†’ stable" },
    ],
    rule: "std > 0.05 â†’ modÃ¨le instable. std < 0.02 â†’ trÃ¨s fiable.",
    frameworks: ["sklearn"],
  },

  # â”€â”€ UTILITAIRES â”€â”€
  {
    method: ".get_params() / .set_params()",
    phase: "Utilitaire",
    phase_icon: "ğŸ”§",
    phase_color: "gray",
    short: "Lire ou modifier les hyperparamÃ¨tres du modÃ¨le.",
    explain: "Utile pour inspecter un modÃ¨le ou dans un pipeline avec GridSearchCV (notation double underscore).",
    examples: [
      { context: "Lire", code: "model.get_params()", learns: "{n_estimators: 100, max_depth: 10, ...}" },
      { context: "Modifier", code: "model.set_params(max_depth=5)", learns: "Change sans recrÃ©er l'objet" },
    ],
    rule: "set_params ne rÃ©-entraÃ®ne pas. Il faut refaire .fit() aprÃ¨s.",
    frameworks: ["sklearn"],
  },
  {
    method: ".summary()",
    phase: "Utilitaire",
    phase_icon: "ğŸ”§",
    phase_color: "gray",
    short: "Affiche l'architecture du rÃ©seau (couches, paramÃ¨tres). Keras uniquement.",
    explain: "Vue d'ensemble du rÃ©seau : chaque couche, sa forme de sortie, et le nombre de paramÃ¨tres entraÃ®nables.",
    examples: [
      { context: "Dense", code: "model.summary()", learns: "Dense(64) â†’ 1216 params, Dropout â†’ 0, Dense(1) â†’ 65" },
    ],
    rule: "VÃ©rifier le nombre total de paramÃ¨tres. Trop â†’ overfitting. Pas assez â†’ underfitting.",
    frameworks: ["keras"],
  },
]

# Also add to GLOSSARY
ML_METHODS.each do |m|
  GLOSSARY.push({
    term: m[:method],
    category: "MÃ©thodes",
    definition: m[:short],
    code: m[:examples]&.first&.dig(:code),
    workflow: case m[:phase]
             when "Apprendre" then "preprocessing"
             when "Transformer" then "preprocessing"
             when "PrÃ©dire" then "linreg"
             when "Ã‰valuer" then "linreg"
             else "pipeline"
             end
  })
end
